---
title: "Video_Project"
output: html_document
author: "Boyu Zheng"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
##Load Data

```{r}
data <- read.csv("Video_project_dataset.csv")
data$REGION_1 = ifelse(data$REGION==1, 1, 0)
data$REGION_2 = ifelse(data$REGION==2, 1, 0)
data$REGION_3 = ifelse(data$REGION==3, 1, 0)
data$REGION_4 = ifelse(data$REGION==4, 1, 0)
data$REGION_5 = ifelse(data$REGION==5, 1, 0)
data$REGION_6 = ifelse(data$REGION==6, 1, 0)
data$REGION_7 = ifelse(data$REGION==7, 1, 0)
data$REGION_8 = ifelse(data$REGION==8, 1, 0)
data$REGION_9 = ifelse(data$REGION==9, 1, 0)
data$CONTROL_1 = ifelse(data$CONTROL==1, 1, 0)
data$CONTROL_2 = ifelse(data$CONTROL==2, 1, 0)
data$CONTROL_3 = ifelse(data$CONTROL==3, 1, 0)
summary(data)
```


##Simple EDA

Except FEMALE (female proportion) and PCT_BA (percentage of people with bachelor degree in student's neighbourhood), most of variables are skewed. Extremely the demographic and income variables like PCT_BLACK, PCT_ASIAN, PCT_ASIAN, POVERTY_RATE.

Demographic variables also have many outliers. COSTT4_A (Cost of Attendance) and PCT_BA have very few outliers.

```{r}
par(mfrow=c(3,3))
hist(data$ADM_RATE, main="Histogram of Admission Rate", ylab="Admission Rate", breaks=20)
hist(data$COSTT4_A, main="Histogram of Average Cost of Attendance", ylab="Average Cost of Attendance",breaks=20)
hist(data$AVGFACSAL, main="Histogram of Average Faculty Salary", ylab="Average Salary",breaks=20)
hist(data$FEMALE, main="Histogram of Female Proportion", ylab="Percentage of Female Student",breaks=20)
hist(data$PCT_BA, main="Histogram of Education Level", ylab="Percentage of people with bachelor degree, over 25",breaks=20)
hist(data$PCT_BORN_US, main="Histogram of Porportion of people born in US", ylab="Percentage of people born in US",breaks=20)
hist(data$PCT_BLACK, main="Histogram of Porportion of Black", ylab="Percentage of Black people in Student's Neighbourhood",breaks=20)
hist(data$PCT_ASIAN, main="Histogram of Porportion of Asian", ylab="Percentage of Asian people in Student's Neighbourhood",breaks=20)
hist(data$POVERTY_RATE, main="Histogram of Poverty Rate", ylab="Poverty Rate",breaks=20)
```

```{r}
par(mfrow=c(2,2))
boxplot(data$ADM_RATE, main="Histogram of Admission Rate", ylab="Admission Rate", horizontal=TRUE)
boxplot(data$COSTT4_A, main="Histogram of Average Cost of Attendance", ylab="Average Cost of Attendance",horizontal=TRUE)
boxplot(data$AVGFACSAL, main="Histogram of Average Faculty Salary", ylab="Average Salary",horizontal=TRUE)
boxplot(data$FEMALE, main="Histogram of Female Proportion", ylab="Percentage of Female Student",horizontal=TRUE)
boxplot(data$PCT_BA, main="Histogram of Education Level", ylab="Percentage of people with bachelor degree, over 25",horizontal=TRUE)
boxplot(data$PCT_BORN_US, main="Histogram of Porportion of people born in US", ylab="Percentage of people born in US",horizontal=TRUE)
boxplot(data$PCT_BLACK, main="Histogram of Porportion of Black", ylab="Percentage of Black people in Student's Neighbourhood",horizontal=TRUE)
boxplot(data$PCT_ASIAN, main="Histogram of Porportion of Asian", ylab="Percentage of Asian people in Student's Neighbourhood",horizontal=TRUE)
boxplot(data$POVERTY_RATE, main="Histogram of Poverty Rate", ylab="Poverty Rate",horizontal=TRUE)
```

##Simple Linear Regression

Except Cost of Attendance (COSTT4_A) and Education level (PCT_BA), we see no significantly visible linear relationship between the variable and admission rate. Both COSTT4_A and PCT_BA have negative relationship with admission rate. 

```{r}
plot(x=data$COSTT4_A,y=data$ADM_RATE,xlab="Average Cost of Attendance", ylab="Admission Rate", main="Scatter plot for Cost vs Admission Rate")
plot(x=data$PCT_BA,y=data$ADM_RATE,xlab="Percentage of People with Bachelor Degree", ylab="Admission Rate", main="Scatter plot for Education Level vs Admission Rate")
plot(x=data$PCT_BORN_US,y=data$ADM_RATE,xlab="Percentage of People Born in US", ylab="Admission Rate", main="Scatter plot for US Proportion vs Admission Rate")
plot(x=data$POVERTY_RATE,y=data$ADM_RATE,xlab="Poverty Rate", ylab="Admission Rate", main="Scatter plot for Poverty Rate vs Admission Rate")
plot(x=data$PCT_WHITE,y=data$ADM_RATE,xlab="Percentage of Black People", ylab="Admission Rate", main="Scatter plot for White vs Admission Rate")
plot(x=data$PCT_ASIAN,y=data$ADM_RATE,xlab="Percentage of Asian People", ylab="Admission Rate", main="Scatter plot for Asian vs Admission Rate")
```

## Main regression model, with F test

Below is our initial regression model, with all basic factors we intend to include. F test result shows that linear relationship exists. However, libear relationship between admission rate and some predictors are not significant, and the model contains too much predictors. We may need a partial F test to examine whether some variables is needed.

```{r}
mod1 <- lm(ADM_RATE ~ CONTROL_1+CONTROL_2+COSTT4_A+AVGFACSAL+FEMALE+PCT_BA+PCT_WHITE+PCT_ASIAN+PCT_BLACK+POVERTY_RATE
           +CONTROL_1*COSTT4_A+CONTROL_1*AVGFACSAL+CONTROL_1*FEMALE+CONTROL_1*PCT_BA+CONTROL_1*PCT_WHITE+CONTROL_1*PCT_ASIAN+CONTROL_1*PCT_BLACK+CONTROL_1*POVERTY_RATE, data=data)
summary(mod1)
```

#Partial F test

First we notice that linear relationship between admission rate and CONTROL_2 or PCT_BA is not significant, so we conduct a partial F-test to test whether we should include them. We cannot reject the null hypothesis that coefficient of these variables are 0, so we decide to exclude them from the linear regression model.
```{r}
mod2 <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+PCT_BLACK+POVERTY_RATE
           +CONTROL_1*COSTT4_A+CONTROL_1*AVGFACSAL+CONTROL_1*FEMALE+CONTROL_1*PCT_WHITE+CONTROL_1*PCT_ASIAN+CONTROL_1*PCT_BLACK+CONTROL_1*POVERTY_RATE, data=data)

mod3 <- lm(ADM_RATE ~ CONTROL_1+CONTROL_2+COSTT4_A+AVGFACSAL+FEMALE+PCT_BA+PCT_WHITE+PCT_ASIAN+PCT_BLACK+POVERTY_RATE
           +CONTROL_1*COSTT4_A+CONTROL_1*AVGFACSAL+CONTROL_1*FEMALE+CONTROL_1*PCT_BA+CONTROL_1*PCT_WHITE+CONTROL_1*PCT_ASIAN+CONTROL_1*PCT_BLACK+CONTROL_1*POVERTY_RATE, data=data)
anova(mod2, mod3)
```

Since the p-value of interaction term between CONTROL_1 and some predictors is not significant,we examine the significance of predictors related to CONTROL_1 (whether the university is public or not). By partial F test, we reject the null hypothesis that the coefficients of predictors related to CONTROL_1 are zero. However, a further partial F test suggest that we could only preserve interaction term between CONTROL_1 and PCT_ASIAN and female.

```{r}
mod4 <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_BLACK+PCT_ASIAN+POVERTY_RATE, data=data)
mod5 <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+PCT_BLACK+POVERTY_RATE
           +CONTROL_1*COSTT4_A+CONTROL_1*AVGFACSAL+CONTROL_1*FEMALE+CONTROL_1*PCT_WHITE+CONTROL_1*PCT_ASIAN+CONTROL_1*PCT_BLACK+CONTROL_1*POVERTY_RATE, data=data)
anova(mod5,mod4)


mod6 <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+POVERTY_RATE
           +CONTROL_1*FEMALE+CONTROL_1*PCT_ASIAN, data=data)
mod7 <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+PCT_BLACK+POVERTY_RATE
           +CONTROL_1*COSTT4_A+CONTROL_1*AVGFACSAL+CONTROL_1*FEMALE+CONTROL_1*PCT_WHITE+CONTROL_1*PCT_ASIAN+CONTROL_1*PCT_BLACK+CONTROL_1*POVERTY_RATE, data=data)
anova(mod7,mod6)
```

Finally, to determine whether we need to include REGION factor, we conducted a partial F test. Although the result is moderately significant, it is a bit too complicated and within T-test, we cannot reject the null hypothesis that the mean of admission rate between each region is not zero. Therefore we decide not to include REGION predictor within our regression model.

```{r}
mod8 <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+POVERTY_RATE+CONTROL_1*FEMALE+CONTROL_1*PCT_ASIAN, data=data)
mod9 <- lm(ADM_RATE ~ REGION_1+REGION_2+REGION_3+REGION_4+REGION_5+REGION_6+REGION_7+REGION_8+CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+POVERTY_RATE+CONTROL_1*FEMALE+CONTROL_1*PCT_ASIAN, data=data)
anova(mod8,mod9)
summary(mod9)
```

Therefore, our final regression model would include following 9 predictors: CONTROL_1 (public university), Cost, Average Faculty Salary, Female Student Proportion, White Student Proportion, Asian Student Proportion, Poverty Rate of Student's Neighbourhood, interaction term between public university and female proportion and interaction term between public university and asian student proportion. This model will have R square equal to 0.23.

If we are not sensitive to a more complex model, we could add region predictors so that we get larger R square and better interpretation of variance of response value.

```{r}
mod <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+POVERTY_RATE
           +CONTROL_1*FEMALE+CONTROL_1*PCT_ASIAN, data=data)
summary(mod)

mod0 <- lm(ADM_RATE ~ REGION_1+REGION_2+REGION_3+REGION_4+REGION_5+REGION_6+REGION_7+REGION_8+CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+POVERTY_RATE
           +CONTROL_1*FEMALE+CONTROL_1*PCT_ASIAN, data=data)
summary(mod0)
```

#Test Linear Regression Assumptions and Transformation of Predictors

```{r}
mod <- lm(ADM_RATE ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+PCT_ASIAN+POVERTY_RATE+CONTROL_1*FEMALE+CONTROL_1*PCT_ASIAN, data=data)
r <- resid(mod)
plot(data$ADM_RATE ~ fitted(mod))
abline(a=0,b=1)
lines(lowess(data$ADM_RATE ~ fitted(mod)), lty=2)
```

```{r}
par(mfrow=c(3,3))
plot(r ~fitted(mod), main="res against fitted", xlab="Fitted", ylab="res.")
plot(r ~ data$ADM_RATE, main="res against Admission Rate", xlab="Admission Rate", ylab="res")
plot(r ~ data$COSTT4_A, main="res against Cost", xlab="Cost", ylab="res")
plot(r ~ data$AVGFACSAL, main="res against Salary", xlab="AVGFACSAL", ylab="res")
plot(r ~ data$PCT_WHITE, main="res against White Proportion", xlab="PCT_WHITE", ylab="res")
plot(r ~ data$PCT_ASIAN, main="res against Asian Proportion", xlab="PCT_ASIAN", ylab="res")
plot(r ~ data$FEMALE, main="res against Female Proportion", xlab="FEMALE", ylab="res")
plot(r ~ data$POVERTY_RATE, main="res against Poverty Rate", xlab="Poverty Rate", ylab="res")
qqnorm(r)
qqline(r)
```

Power Transform test indicates that log transformation is needed in order to improve the normality of predictors.
```{r}
data<-data[which(data$ADM_RATE != 0),]
library(car)
p <-powerTransform(cbind(data$ADM_RATE,data$COSTT4_A,data$AVGFACSAL,data$FEMALE,data$PCT_WHITE,data$PCT_ASIAN,data$POVERTY_RATE)~1)
summary(p)
```

Since the residual plot of some varibles are basically normal, we choose to transform ADM_RATE, POVERTY_RATE and PCT_ASIAN. We saw a rise in R square.
```{r}
mod <- lm(log(ADM_RATE) ~ CONTROL_1+COSTT4_A+AVGFACSAL+FEMALE+PCT_WHITE+log(PCT_ASIAN)+log(POVERTY_RATE)+CONTROL_1*FEMALE+CONTROL_1*log(PCT_ASIAN), data=data)
summary(mod)

```





